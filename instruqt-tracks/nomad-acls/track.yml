slug: nomad-acls
id: vlqq3najdjpp
type: track
title: Nomad Access Control Lists (ACLs)
teaser: Learn how to control access to Nomad with Access Control Lists (ACLs).
description: |-
  Nomad is a flexible workload orchestrator that enables an organization to easily deploy and manage any containerized or legacy application using a single, unified workflow. Nomad can run a diverse workload of Docker, non-containerized, microservice, and batch applications.

  This track will show you how to control access to Nomad with Access Control Lists (ACLs).

  Before running this track, we suggest you run the [Nomad Basics](https://instruqt.com/hashicorp/tracks/nomad-basics), [Nomad Simple Cluster](https://instruqt.com/hashicorp/tracks/nomad-simple-cluster), and [Nomad Multi-Server Cluster](https://instruqt.com/hashicorp/tracks/nomad-multi-server-cluster) tracks.
icon: https://storage.googleapis.com/instruqt-hashicorp-tracks/logo/nomad.png
tags:
- nomad
- security
- acls
owner: hashicorp
developers:
- lhaig@hashicorp.com
- roger@hashicorp.com
private: true
published: true
challenges:
- slug: run-the-servers-and-clients
  id: 5efmxtpkfxlm
  type: challenge
  title: Confirm the Agents are running.
  teaser: Confirming that the Agents are configured and running.
  assignment: |-
    Before we begin securing our Nomad cluster, lets verify that all 3 servers and both clients are running.
    Run all the folowing commands in the 'Server 1' tab

    Check the servers:
    ```
    nomad server members
    ```
    You should see 3 servers that are all alive. server1 should be the leader.

    Then check the client nodes:
    ```
    nomad node status
    ```
    You should see two client nodes.

    We have run a job that we will use as part of the challenges to visualize the use of ACL's
    Check the job status
    ```
    nomad status
    ```
    You should see a job with the id of 'redis'.

    In the next challenge, you will configure ACLs for the Nomad cluster.
  notes:
  - type: text
    contents: |-
      In this track, you'll learn how to control access to Nomad with Access Control Lists (ACLs).

      The first challenge will run 3 Nomad servers and 2 Nomad clients for you. All you'll need to do is check that they are running.

      In the following challenges, you will configure and then use Nomad ACLs.
  - type: text
    contents: |-
      We've already started a cluster with three servers and two clients for you.

      We have run a job called redis
  tabs:
  - title: Config Files
    type: code
    hostname: nomad-server-1
    path: /root/nomad/
  - title: Server 1
    type: terminal
    hostname: nomad-server-1
  - title: Server 2
    type: terminal
    hostname: nomad-server-2
  - title: Server 3
    type: terminal
    hostname: nomad-server-3
  - title: Client 1
    type: terminal
    hostname: nomad-client-1
  - title: Client 2
    type: terminal
    hostname: nomad-client-2
  - title: Nomad UI
    type: service
    hostname: nomad-server-1
    port: 4646
  difficulty: basic
  timelimit: 1800
- slug: configure-server-acls
  id: rfb3dvxmxuyp
  type: challenge
  title: Configure Nomad Server ACLs
  teaser: Configure Nomad Server ACLs.
  assignment: |-
    The APIs needed to manage policies and tokens are not enabled until ACLs are enabled.
    We need to enable the ACL configuration for our cluster

    Let's start by configiuring ACLs in our Nomad Servers first.

    To do this we need to enable acl in the acl stanza of each server file. Go to each "Server Config" tab and add the following section to the end of the file, below the server stanza.
    ```
    acl {
      enabled = true
    }
    ```
    In a multi-region configuration you will need to add the "authoritative_region" configuration to the server stanza. Since we only have one region this is not strictly nessesary. We will however make the change to make it clear how it should look.

    Lets add this configuration now.

    For each server open the "Server Config" tab and edit the server stanza to look like this.

    ```
    server {
      enabled = true

      # Self-elect, should be 3 or 5 for production
      bootstrap_expect = 3
      authoritative_region = "global"
    }
    ```
    Now we need to restart the nomad servers one at a time. Complete the following steps for each server.
    ```
    systemctl restart nomad
    ```
    If you run the
    ```
    nomad server members
    ```
    command in the "Server 1" Tab what is the result?

    You will not be able to query the job status either.

    If everything is configured correctly you will get an access denied error.
    This is the expected behavior as Nomad ACLs is "Deny by default". We will be fixing this in a later challenge.

    To make sure the process is running we can run the following command on each server console tab.

    ```
    ps -ef | grep nomad
    ```

    The result should be similar to this on each server.

    ```
    root@nomad-server-1:~# ps -ef | grep nomad
    root      2203     1  1 10:28 ?        00:01:25 /usr/local/bin/nomad agent -config /etc/nomad.d
    root      3369  3345  0 12:06 pts/0    00:00:00 grep nomad
    root@nomad-server-1:~#
    ```

    This confirms tha the agents are running.

    In the next challenge, you will configure the nomad client servers for utilizing ACLs.
  notes:
  - type: text
    contents: In this challenge, you will configure the Nomad Servers for utilizing
      ACLs.
  - type: text
    contents: In the next challenge, you will configure the Nomad Clients for utilizing
      ACLs.
  tabs:
  - title: Server 1 Config
    type: code
    hostname: nomad-server-1
    path: /etc/nomad.d/server1.hcl
  - title: Server 1
    type: terminal
    hostname: nomad-server-1
  - title: Server 2 Config
    type: code
    hostname: nomad-server-2
    path: /etc/nomad.d/server2.hcl
  - title: Server 2
    type: terminal
    hostname: nomad-server-2
  - title: Server 3 Config
    type: code
    hostname: nomad-server-3
    path: /etc/nomad.d/server3.hcl
  - title: Server 3
    type: terminal
    hostname: nomad-server-3
  - title: Nomad UI
    type: service
    hostname: nomad-server-1
    port: 4646
  difficulty: basic
  timelimit: 1800
- slug: configure-client-acls
  id: ncufcvo3ycxz
  type: challenge
  title: Configure Nomad Client ACLs
  teaser: Configure Nomad Client ACLs.
  assignment: |-
    Now that we have the servers using ACLs we need to configure the Clients to use them as well.

    Let's get started.

    We need to enable acl in the acl stanza of each client file. Go to each client node config tab and add the following section to the end of the file, below the client stanza.
    ```
    acl {
      enabled = true
    }
    ```
    That is all configuration that needs to be done.

    Now you need to restart the nomad clients one at a time as we did for the servers. Complete the following steps for each server.
    ```
    systemctl restart nomad
    ```
    After you have restarted the Nomad Agents.

    Run the following command in the "Server1" tab.
    ```
    nomad node status
    ```
    What is the result?

    You will see the same error that we recieved when we tried to check the server status earlier.

    Run the same command we did in the server challenge on both client node consoles to make sure that the Nomad process is running.

    ```
    ps -ef | grep nomad
    ```

    The result should be similar to this on each client.

    ```
    root@nomad-client-1:~# ps -ef | grep nomad
    root      2203     1  1 10:28 ?        00:01:25 /usr/local/bin/nomad agent -config /etc/nomad.d
    root      3369  3345  0 12:06 pts/0    00:00:00 grep nomad
    root@nomad-client-1:~#
    ```

    This confirms tha the agents are running.

    In the next challemge we will bootstrap the cluster ACL API and create our first management token
  notes:
  - type: text
    contents: In this challenge, you will configure the Nomad Clients for utilizing
      ACLs.
  - type: text
    contents: In the next challenge, you will bootstrap the Nomad Cluster ACLs.
  tabs:
  - title: Server 1
    type: terminal
    hostname: nomad-server-1
  - title: Client 1 Config
    type: code
    hostname: nomad-client-1
    path: /etc/nomad.d/client1.hcl
  - title: Client 1
    type: terminal
    hostname: nomad-client-1
  - title: Client 2 Config
    type: code
    hostname: nomad-client-2
    path: /etc/nomad.d/client2.hcl
  - title: Client 2
    type: terminal
    hostname: nomad-client-2
  - title: Nomad UI
    type: service
    hostname: nomad-server-1
    port: 4646
  difficulty: basic
  timelimit: 1800
- slug: bootstrap-acls
  id: agli9we12h2m
  type: challenge
  title: Bootstrap Nomad ACLs
  teaser: Bootstrap Nomad ACLs.
  assignment: |-
    Now that we have the servers and Clients using ACLs we need to bootstrap the ACL system.

    Let's get started.

    To enable the API we need to run the "nomad bootstrap" command. This will create the inital management token for us to use to setup ACL in general.
    This token information should be kept in a safe place as it has "FULL UNRESTRICTED" access to your cluster.

    Let us ACL bootstrap the cluster.

    Open the "Server 1" tab and run the following.

    ```
    cd nomad
    nomad acl bootstrap > acl_token.txt
    ```

    This will bootstrap the cluster ACL API and export the bootstrap credentials into a file called "acl_token.txt" we will be using that to continue the challenge.

    We now need to enable the anonymous policy so that we can interact with the cluster using the nomad cli.
    To do this we need to export the "Secret ID" of our token as an environemnt variable called "NOMAD_TOKEN" and then use "curl" to create the policy.

    Open the "Server 1 Edit" tab and you will see two files:
      * anonymous.json
      * acl_token.txt

    Open the anonymous.json file.
    It should look like this.
    ```
    {
      "Name": "anonymous",
      "Description": "Allow read-only access for anonymous requests",
      "Rules": "
        namespace \"default\" {
          policy = \"read\"
        }
        agent {
          policy = \"read\"
        }
        node {
          policy = \"read\"
        }
      "
    }

    ```

    As you can see this policy allows read access to three rules
    * namespace
    * agent
    * node

    We now need to apply this policy to the cluster.
    To do this we will need to create an "Authenticated" connection to the server that allows us to install policies.

    Lets do that.

    Open the acl_token.txt file
    The file should look something like this.
    ```
    Accessor ID  = 6fa2c331-a156-9238-ed2d-fed666518934
    Secret ID    = 187abe9e-abb5-a917-5176-99d7eb642b44
    Name         = Bootstrap Token
    Type         = management
    Global       = true
    Policies     = n/a
    Create Time  = 2020-01-09 17:58:06.854257747 +0000 UTC
    Create Index = 29
    Modify Index = 29
    ```
    Copy the "Secret ID" token.

    Open the "Server1" console and run **ALL** the next commands in the "Server 1" console tab.
    ```
    export NOMAD_TOKEN="PLACE_YOUR_SECURE_ID_HERE"
    ```

    We now need to install the policy.

    ```
    curl --request POST --data @anonymous.json -H "X-Nomad-Token: $NOMAD_TOKEN" http://localhost:4646/v1/acl/policy/anonymous
    ```

    To verify that the policy has been applied, run the following command to make sure.
    ```
    curl http://localhost:4646/v1/jobs
    ```
    It should not give an error.

    Now we should be able to run our command from before.

    Check the state of the servers.
    ```
    nomad server members
    ```
    You should see the 3 servers that are all alive. One of the servers will be a leader.

    Check the node status.
    ```
    nomad node status
    ```
    You should see the 2 client servers.

    In the next challenge, you will see how the Nomad ACLs restrict what different users can do in Nomad.
  notes:
  - type: text
    contents: |-
      In this challenge, you will bootstrap the cluster to utilize ACLs.

      The ACL system uses a whitelist or default-deny model. This means by default no permissions are granted. For clients making requests without ACL tokens, we may want to grant some basic level of access.
  - type: text
    contents: In the final challenge, you will see how the ACLs restrict what different
      users can do in Nomad.
  tabs:
  - title: Server 1 Edit
    type: code
    hostname: nomad-server-1
    path: /root/nomad/
  - title: Server 1
    type: terminal
    hostname: nomad-server-1
  - title: Server 2
    type: terminal
    hostname: nomad-server-2
  - title: Server 3
    type: terminal
    hostname: nomad-server-3
  - title: Client 1
    type: terminal
    hostname: nomad-client-1
  - title: Client 2
    type: terminal
    hostname: nomad-client-2
  - title: Nomad UI
    type: service
    hostname: nomad-server-1
    port: 4646
  difficulty: basic
  timelimit: 1800
- slug: use-acls
  id: 2dzqorlvompb
  type: challenge
  title: Using Nomad ACLs
  teaser: See how Nomad ACLs restrict what different users can do in Nomad.
  assignment: |-
    Now, let's see the Nomad ACLs in action.

    In the last section we created an anonymous ACL policy that allowed any anonymous unauthenticated connection to have read only access to the cluster.
    To confirm we still have this access
    Open the 'Server 2' tab and run the following commands.
    ```
    nomad job status
    ```
    You should see the status of the running redis job.

    and then run.
    ```
    nomad agent-info
    ```
    This is not an ideal situation as anyone with access tot he API could get quite a bit of information about the cluster and its jobs.

    Let us remove this access to secure our cluster once again.

    In the 'Server 1' console tab run the following commands.

    Let us export our admin token so we can run the commands.
    ```
    cd nomad
    export NOMAD_TOKEN=`cat acl_token.txt | grep Secret | awk '{print$4}'`
    ```
    We will now delete the anonymous policy
    ```
    nomad acl policy delete anonymous
    ```
    Once this has run go back to the 'Server 2' termminal tab and try to run
    ```
    nomad agent-info
    ```
    You should recive an access denied error.

    We will now create 2 policies one for our dev team and one for ops.

    For the purpose of this example we will restrict the dev team to not be able to stop any job.

    In the Config Files Editor you will now see 2 new files in the Lists
     * dev_policy.hcl
     * ops_policy.hcl

    These two policy files will give each of the dev or ops team different permissions to the cluster.

    The dev team will get Read only access to the cluster.
    The Ops team will get Full access to the jobs.

    Let us apply the policies.

    We will use the nomad client to apply the policies to the cluster.

    Open the `Server 1` terminal tab and run the following commands in that tab.

    To apply the dev policy run the following command.
    ```
    nomad acl policy apply -description "Dev Read Only" devRO dev_policy.hcl
    ```
    We have named the policy `devRO`.

    To apply the Ops policy run.
    ```
    nomad acl policy apply -description "OPS Read write" opsWR ops_policy.hcl
    ```
    We have named the policy `opsRW`

    Run the following command to see a list of the policies that are now applied.

    ```
    nomad acl policy list
    ```

    There should be a list of the 2 policies we just applied.

    To use these policies we need to create some client tokens for the dev and ops team.

    It is very easy to create these tokens using the nomad client.

    Open the ` Server 1` terminal tab and run the following commands.
    ```
    nomad acl token create -name="Dev Ro" -type="client" -policy="devRO" > devro_token.txt
    ```

    This will create our Dev read only token and apply the devRO policy to this token.
    We export the token to a text file so we can use it a bit later to test.

    We will do the same for the Ops Token by running the following command.
    ```
    nomad acl token create -name="Ops RW" -type="client" -policy="opsRW" > opsrw_token.txt
    ```

    If you now run ```nomad acl token list``` you should see a list with the two new tokens being there.

    We can now test the teams access.

    In the `Server 2` terminal tab export the dev token type the commands below
    ```
    cd nomad
    export NOMAD_TOKEN="
    ```
    Open the `Server Config` tab open the devro_token.txt file and copy the `Secret ID` token and paste it after the opening ` " ` mark and then close the ` " ` and hit return.

    If you now run ```nomad job status``` you should see the redis job listed again.

    If you try to run ```nomad job stop redis``` you should get a permission denied error.

    Now lets test the ops teams access.

    In the `Server 3` terminal tab export the dev token by typing the commands below
    ```
    cd nomad
    export NOMAD_TOKEN="
    ```
    Open the `Server Config` tab open the opsrw_token.txt file and copy the `Secret ID` token and paste it after the opening ` " ` mark and then close the ` " ` and hit return.

    If you now run ```nomad job status``` you should see the redis job listed again.

    If you try to run ```nomad job stop redis``` it should stop the job.

    If you try to run ```nomad job start redis``` the job should start again.

    As you can see the ACL permissions can be adjusted applied in many ways and it is recccomended that you read up further about the policies here. [Nomad ACLs](https://www.nomadproject.io/guides/security/acl.html)

    Congratulations on finishing the Nomad ACLs track!
  notes:
  - type: text
    contents: |-
      In this final challenge, you will see how the ACLs restrict what different users can do in Nomad.
  - type: text
    contents: |-
      We will be applying a Developer Policy and also and Operations Policy to the cluster usign the Nomad client.

      We wil create some client tokens for a develoepr role and one for an Opersatios role and assign these to the corresponding policy.
  - type: text
    contents: |-
      We will then use these token to perform som basic actions on the cluster.
  tabs:
  - title: Config Files
    type: code
    hostname: nomad-server-1
    path: /root/nomad/
  - title: Server 1
    type: terminal
    hostname: nomad-server-1
  - title: Server 2
    type: terminal
    hostname: nomad-server-2
  - title: Server 3
    type: terminal
    hostname: nomad-server-3
  - title: Nomad UI
    type: service
    hostname: nomad-server-1
    port: 4646
  difficulty: basic
  timelimit: 1800
checksum: "13439494581140262406"
