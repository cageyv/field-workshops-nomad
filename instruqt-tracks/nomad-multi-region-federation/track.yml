slug: nomad-federation
id: xc0sasoj8opb
type: track
title: Nomad Multi-Region Federation
teaser: In this track you will federate two individual Nomad cluster then deploy a
  multi-region job.
description: |-
  Nomad is the first and only orchestrator on the market with complete and fully-supported federation capabilities for production.
  Nomad operates at a regional level and provides first-class support for federation. Federation enables users to submit jobs or interact with the HTTP API targeting any region, from any server, even if that server resides in a different region.
icon: https://storage.googleapis.com/instruqt-frontend/img/tracks/default.png
tags: []
owner: hashicorp
developers:
- tharris@hashicorp.com
private: true
published: false
show_timer: true
challenges:
- slug: federation
  id: bmpqlkguhsn2
  type: challenge
  title: Federate two Nomad Clusters
  teaser: |
    Nomad 0.12 introduces our breakthrough Multi-Cluster Deployment feature, which makes Nomad the first and only orchestrator on the market with complete and fully-supported federation capabilities for production.
  assignment: |2-

    In the "Nomad_Server_West" tab, verify the health of the nomad cients, then repeat the command in the "Nomad_Server_East" tab. The node status command should return two nodes in each region.
    ```
    nomad node status
    ```
    Then check the status of the servers in each region. Please copy the IP address of the server in the West Region, as you will need this in the next step to federate the clusters.
    ```
    nomad server members
    ```
    In the "Nomad_Server_East" tab, federate the two regions by using the server join command:
    ```
    nomad server join <nomad-server-west-ip>:4648
    ```
    Verify the clusters have been federated. Run the below command in both server tabs. The output of the command should show the servers from both regions:
    ```
    nomad server members
    ```
    From the Nomad cluster in the west region, try to run the nomad status command to check the status of jobs in the east region. (you should see no running jobs at this point)
    ```
    nomad status -region="east"
    ```
    You are also able to run   `nomad status -region="west"` from the east server. As you can see, regions are addressable from different regions, a key tenet of the value of federation. Allowing control over many clusters from a single point of access, ensuring a more holistic view and management the environment.
  notes:
  - type: text
    contents: |-
      Nomad 0.12 introduces our breakthrough Multi-Cluster Deployment feature, which makes Nomad the first and only orchestrator on the market with complete and fully-supported federation capabilities for production.

      In this challenge you will federate two Nomad Clusters which will enable you to submit jobs or interact with the API, targeting any region, from any server, even if that server resides in a different region.
  tabs:
  - title: Config Files
    type: code
    hostname: nomad-server-1-west
    path: /etc/nomad.d/
  - title: Nomad_Server_West
    type: terminal
    hostname: nomad-server-1-west
  - title: Nomad_Server_East
    type: terminal
    hostname: nomad-server-1-east
  - title: Nomad_Client_1_West
    type: terminal
    hostname: nomad-client-1-west
  - title: Nomad_Client_1_East
    type: terminal
    hostname: nomad-client-2-west
  - title: Nomad UI_West
    type: service
    hostname: nomad-server-1-west
    port: 4646
  - title: Nomad UI_East
    type: service
    hostname: nomad-server-1-east
    port: 4646
  difficulty: basic
  timelimit: 1700
- slug: multi-region-deployments
  id: 5fau0q6nqev7
  type: challenge
  title: Multi Region Deployments
  teaser: |
    Deploy a multi-region job
  assignment: |-
    In this challenge you will deploy a multi-region-job. Please read the notes for an explanation of multi-region concepts.

    Inspect the ```/root/nomad/multi-redis.nomad``` job file in the editor.

    The job will deploy to both regions. The `max_parallel` field of the strategy block restricts Nomad to deploy to the regions one at a time.
    If either of the region deployments fail, both regions will be marked as `failed`. The job will deploy to the region the the order that they
    have been defined. Since in this case,`max_parallel` is set to `1`, the `west` region will be deployed before the `east` region regardless of
    whether the job is started from the west server or the east server.

    The `count` field for each region is interpolated for each region, replacing the `count = 0` in the task group count.
    The job's update block uses the default `task states` value to determine if the job is healthy; if you configured a Consul
    service with health checks you could use that instead. Run this command in the "Nomad_Server_West" tab, for the sake of the check scripts.

    ```
    nomad run /root/nomad/multi-redis.nomad
    ```
    Check the job status in the east region. Note that there are no running allocations in the east region, and that the status is `pending` because the east region is waiting for the west region to complete.
    The command can be run from a server in either region, but for the sake of the challenges check scripts, please run this in the
            "Nomad_Server_East" tab.
    ```
    nomad job status -region east example
    ```
    watch the job status in the west region. You should observe running allocations.
    ```
    watch nomad job status -region west example
    ```
    The west region should be healthy 10 seconds after the task state for all tasks switches to `running`. the status for the west region will transition to `blocked` and the east region`s deployment will become `running`. Once the east region`s deployment has completed, both regions will transition to `successful`

    ```
    Multiregion Deployment
    Region  ID        Status
    east    82a0d743  successful
    west    0dee812a  successful
    ```
  notes:
  - type: text
    contents: |-
      Federated Nomad clusters are members of the same gossip cluster but not the same raft/consensus cluster; they don't share their data stores. Each `region` in a multi-region deployment gets an independent copy of the job, parameterized with the values of the region stanza. Nomad regions coordinate to rollout each region's deployment using rules determined by the strategy stanza.

      A single region deployment using one of the various upgrade strategies begins in the `running state` and ends in either the `successful` state if it succeeds, the canceled state if another deployment supersedes it before it is `complete`, or the `failed` state if it fails for any other reason. A `failed` single region deployment may automatically revert to the previous version of the job if its update stanza has the `auto_revert` setting.
  - type: text
    contents: In a multi-region deployment, regions begin in the `pending state`.
      This allows Nomad to determine that all regions have accepted the job before
      continuing. At this point, up to `max_parallel` regions will enter into the
      `running` state. When each region completes its local deployment, it enters
      a `blocked` state where it waits until the last region has completed the deployment.
      The final region will unblock the regions to mark them as successful.
  tabs:
  - title: Config Files
    type: code
    hostname: nomad-server-1-west
    path: /root/nomad
  - title: Nomad_Server_West
    type: terminal
    hostname: nomad-server-1-west
  - title: Nomad_Server_East
    type: terminal
    hostname: nomad-server-1-east
  - title: Nomad_Client_1_West
    type: terminal
    hostname: nomad-client-1-west
  - title: Nomad_Client_1_East
    type: terminal
    hostname: nomad-client-2-west
  - title: Nomad UI_West
    type: service
    hostname: nomad-server-1-west
    port: 4646
  - title: Nomad UI_East
    type: service
    hostname: nomad-server-1-east
    port: 4646
  difficulty: basic
  timelimit: 1700
- slug: simulate-failed-deployment
  id: xymwi5jnxnya
  type: challenge
  title: Simulate a Failed Deployment
  teaser: |
    Deploy a multi-region job which will simulate a failed deployment in the east region.
  assignment: |-
    In this challenge you will deploy a multi-region-job.
    The `multi-redis.nomad` job file has been updated with the addition a new task group. The taskgroup is called "sidecar". You can view the job in the config tab. (file is located at on the ```west``` server)

    With the ```/root/nomad/multi-redis.nomad``` file open, change the multiregion stratedy to ```fail_local```. e.g:

    ```
    strategy {
        max_parallel = 1
        on_failure   = "fail_local"
    }
    ```
    Please note the template stanza in the `sidecar` group. The simple script that is passed to the docker container ensures the allocation will always fail in the `east` region.

    Save and close the file.

    Now run the job. This can be run from a server located in either region, but for the sake of the challenges check scripts, please run this in the "Nomad_Server_West" tab:
    ```
    nomad job run /root/nomad/multi-redis.nomad
    ```

    Check the status. As with the previous version of the job, you should see the deployment in the west in the `running` status and the deployment in the east in `pending`.
    Eventually, the east region deployment will run and then fail. Because on_failure was set to `fail_local`, the west region remains in a `blocked` state:
    ```
    watch nomad job status -region west example
    ```
    You can either fix the job and redeploy, or accept the west deployment in its current state by using the nomad deployment unblock command.
    ```
    nomad deployment unblock -region west <deployment-id>
    ```
    Check the status again and the west region should now be marked as successful:
    ```
    nomad job status -region west example
    ```
  notes:
  - type: text
    contents: In this challenge you will simulate a failed deployment when deploying
      a multi-region job. For further information, please check out the HashiCorp
      Learn guide on which this lab was based on - https://learn.hashicorp.com/tutorials/nomad/multiregion-deployments
  tabs:
  - title: Config Files
    type: code
    hostname: nomad-server-1-west
    path: /root/nomad
  - title: Nomad_Server_West
    type: terminal
    hostname: nomad-server-1-west
  - title: Nomad_Server_East
    type: terminal
    hostname: nomad-server-1-east
  - title: Nomad_Client_1_West
    type: terminal
    hostname: nomad-client-1-west
  - title: Nomad_Client_1_East
    type: terminal
    hostname: nomad-client-2-west
  - title: Nomad UI_West
    type: service
    hostname: nomad-server-1-west
    port: 4646
  - title: Nomad UI_East
    type: service
    hostname: nomad-server-1-east
    port: 4646
  difficulty: basic
  timelimit: 7200
checksum: "901170275656092073"
